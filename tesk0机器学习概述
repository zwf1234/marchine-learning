机器学习综述
一 机器学习的分类
1.	监督学习
监督学习是指利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程，也称为监督训练或有教师学习。在监督学习的过程中会提供对错指示，通过不断地重复训练，使其找到给定的训练数据集中的某种模式或规律，当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求包括输入和输出，主要应用于分类和预测。
2.	非监督学习
与监督学习不同，在非监督学习中，无须对数据集进行标记，即没有输出。其需要从数据集中发现隐含的某种结构，从而获得样本数据的结构特征，判断哪些数据比较相似。因此，非监督学习目标不是告诉计算机怎么做，而是让它去学习怎样做事情。
3.	半监督学习
半监督学习是监督学习和非监督学习的结合，其在训练阶段使用的是未标记的数据和已标记的数据，不仅要学习属性之间的结构关系，也要输出分类模型进行预测。
4.	强化学习
强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是机器学习的范式和方法论之一，用于描述和解决智能体（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题.
二 机器学习模型
机器学习 = 数据（data） + 模型（model） + 优化方法（optimal strategy）
三 常见的机器学习算法
Linear Algorithms，Decision Tree，SVM，Naive Bayes Algorithms，kNN，Clustering Algorithms，K-Means，Random Forest，Dimensionality Reduction Algorithms，Gradient Boosting algorithms，Deep Learning Algorithms
可参考网址：https://blog.csdn.net/weixin_39012047/article/details/81915204
四 机器学习损失函数

可参考网址：
https://blog.csdn.net/perfect1t/article/details/88199179
https://blog.csdn.net/shenxiaoming77/article/details/51614601
五 机器机器学习的评价指标
可参考网址：https://blog.csdn.net/weixin_39910711/article/details/82940210
六 机器机器学习的评价指标
AUC(Area Under Curve)
AUC就是ROC曲线下的面积. 真实情况下，由于数据是一个一个的，阈值被离散化，呈现的曲线便是锯齿状的，当然数据越多，阈值分的越细，”曲线”越光滑.
 
用AUC判断分类器（预测模型）优劣的标准: AUC = 1 是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器. 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值. AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测.
七 机器学习模型选择
交叉验证、k-折叠交叉验证、Bias与Variance，欠拟合与过拟合。
欠拟合一般表示模型对数据的表现能力不足，通常是模型的复杂度不够，并且Bias高，训练集的损失值高，测试集的损失值也高.
过拟合一般表示模型对数据的表现能力过好，通常是模型的复杂度过高，并且Variance高，训练集的损失值低，测试集的损失值高.
解决方法：
增加训练样本: 解决高Variance情况；
减少特征维数: 解决高Variance情况；
增加特征维数: 解决高Bias情况；
增加模型复杂度: 解决高Bias情况；
减小模型复杂度: 解决高Variance情况。
八 机器学习参数调优
1.网格搜索
一种调参手段；穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果
2.随机搜索
与网格搜索相比，随机搜索并未尝试所有参数值，而是从指定的分布中采样固定数量的参数设置。它的理论依据是，如果随即样本点集足够大，那么也可以找到全局的最大或最小值，或它们的近似值。通过对搜索范围的随机取样，随机搜索一般会比网格搜索要快一些。
3.贝叶斯优化算法
贝叶斯优化用于机器学习调参由J. Snoek(2012)提出，主要思想是，给定优化的目标函数(广义的函数，只需指定输入和输出即可，无需知道内部结构以及数学性质)，通过不断地添加样本点来更新目标函数的后验分布(高斯过程,直到后验分布基本贴合于真实分布。简单的说，就是考虑了上一次参数的信息，从而更好的调整当前的参数。












