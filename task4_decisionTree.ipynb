{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numbers\n",
    "import warnings\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \"\"\"自定的树结构,用来保存决策树.\n",
    "    \n",
    "    Paramters:\n",
    "    ----------\n",
    "    col: int, default(-1)\n",
    "        当前使用的第几列数据\n",
    "    \n",
    "    val: int or float or str, 分割节点\n",
    "        分割节点的值, \n",
    "        int or float : 使用大于进行比较 \n",
    "        str : 使用等于模式\n",
    "    \n",
    "    LeftChild: DecisionTree\n",
    "        左子树, <= val\n",
    "    \n",
    "    RightChild: DecisionTree\n",
    "        右子树, > val\n",
    "    \n",
    "    results: \n",
    "    \"\"\"\n",
    "    def __init__(self, col=-1, val=None, LeftChild=None, RightChild=None, result=None):\n",
    "        self.col = col\n",
    "        self.val = val\n",
    "        self.LeftChild = LeftChild\n",
    "        self.RightChild = RightChild\n",
    "        self.result = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeClassifier(object):\n",
    "    \"\"\"使用基尼指数的分类决策树接口.\n",
    "    \n",
    "    Paramters:\n",
    "    ---------\n",
    "    max_depth : int or None, optional(dafault=None)\n",
    "        表示决策树的最大深度. None: 表示不设置深度,可以任意扩展,\n",
    "        直到叶子节点的个数小于min_samples_split个数.\n",
    "\n",
    "    min_samples_split : int, optional(default=2)\n",
    "        表示最小分割样例数.\n",
    "        if int, 表示最小分割样例树,如果小于这个数字,不在进行分割.\n",
    "\n",
    "    min_samples_leaf : int, optional (default=1)\n",
    "        表示叶节点最少有min_samples_leaf个节点树,如果小于等于这个数,直接返回.\n",
    "        if int, min_samples_leaf就是最小样例数.\n",
    "\n",
    "    min_impurity_decrease : float, optional (default=0.)\n",
    "        分割之后基尼指数大于这个数,则进行分割.\n",
    "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
    "                        - N_t_L / N_t * left_impurity)\n",
    "\n",
    "    min_impurity_split : float, default=1e-7\n",
    "        停止增长的阈值,小于这个值直接返回.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape (n_classes,) or a list of such arrays\n",
    "        表示所有的类\n",
    "    \n",
    "    feature_importances_ : ndarray of shape (n_features,)\n",
    "        特征重要性, 被选择最优特征的次数,进行降序.\n",
    "    \n",
    "    tree_ : Tree object\n",
    "        The underlying Tree object.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=1e-7):        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        self.classes_ = None\n",
    "        self.max_features_ = None\n",
    "        self.decision_tree = None\n",
    "        self.all_feats = None\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, check_input=True):\n",
    "        \"\"\"使用X和y训练决策树的分类模型.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like} of shape (n_samples, n_features)\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32``\n",
    "            \n",
    "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels) as integers or strings.\n",
    "        \n",
    "        check_input : bool, (default=True)\n",
    "            Allow to bypass several input checking.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Fitted estimator.\n",
    "        \"\"\"\n",
    "        if isinstance(X, list):\n",
    "            X = self.__check_array(X)\n",
    "        if isinstance(y, list):\n",
    "            y = self.__check_array(y)\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"输入的数据X和y长度不匹配\")\n",
    "        \n",
    "        self.classes_ = list(set(y))\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "        \n",
    "        data_origin = np.c_[X, y]\n",
    "#         print (data_origin)\n",
    "        self.all_feats = [i for i in range(X.shape[1])]\n",
    "        self.max_features_ = X.shape[0]\n",
    "        \n",
    "        data = copy.deepcopy(data_origin)\n",
    "        self.decision_tree = self.__build_tree(data, 0)\n",
    "\n",
    "    # add function\n",
    "    def single(self, data, tree):\n",
    "            if tree.result != None:\n",
    "                return tree.result\n",
    "            else:\n",
    "                branch = None\n",
    "                v = data[tree.col]\n",
    "                if isinstance(v, int) or isinstance(v, float):\n",
    "                    if v <= tree.val:\n",
    "                        branch = tree.LeftChild\n",
    "                    else:\n",
    "                        branch = tree.RightChild\n",
    "                else:\n",
    "                    if v == tree.val:\n",
    "                        branch = tree.LeftChild\n",
    "                    else:\n",
    "                        branch = tree.RightChild\n",
    "                return self.single(data, branch)\n",
    "    \n",
    "    def __predict_one(self, input_x):\n",
    "        \"\"\"预测一个样例的返回结果.\n",
    "        \n",
    "        Paramters:\n",
    "        ---------\n",
    "        input_x : list or np.ndarray\n",
    "            需要预测输入数据\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        class : 对应的类\n",
    "        \"\"\"\n",
    "        \n",
    "        tree = self.decision_tree\n",
    "        #============================= show me your code =======================\n",
    "        # here\n",
    "        pre_y = self.single(input_x, tree)\n",
    "        #============================= show me your code =======================\n",
    "        return pre_y\n",
    "    \n",
    "    \n",
    "    def predict(self, test):\n",
    "        \"\"\"预测函数,\n",
    "        \n",
    "        Paramters:\n",
    "        ---------\n",
    "        test: {array-like} of shape (n_samples, n_features)\n",
    "        \n",
    "        Returns:\n",
    "        result : np.array(list) \n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for i in range(len(test)):\n",
    "            result.append(self.__predict_one(test[i]))\n",
    "        return np.array(result)\n",
    "    \n",
    "    \n",
    "    def score(self, vali_X, vali_y):\n",
    "        \"\"\"验证模型的特征,这里使用准确率.\n",
    "        Parameters\n",
    "        ----------\n",
    "        vali_X : {array-like} of shape (n_samples, n_features)\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32``\n",
    "\n",
    "        vali_y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values (class labels) as integers or strings.\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        score : float, 预测的准确率\n",
    "        \"\"\"\n",
    "        vali_y = np.array(vali_y)\n",
    "        pre_y = self.predict(vali_X)\n",
    "        pre_score = 1.0 * sum(vali_y == pre_y) / len(vali_y)\n",
    "        return pre_score\n",
    "    \n",
    "    \n",
    "    def __build_tree(self, data, depth):\n",
    "        \"\"\"创建决策树的主要代码\n",
    "        \n",
    "        Paramters:\n",
    "        ---------\n",
    "        data : {array-like} of shape (n_samples, n_features) + {label}\n",
    "            The training input samples. Internally, it will be converted to\n",
    "            ``dtype=np.float32``\n",
    "        \n",
    "        depth: int, 树的深度\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        DecisionTree\n",
    "            \n",
    "        \"\"\"        \n",
    "        labels = np.unique(data[:,-1])\n",
    "        # 只剩下唯一的类别时,停止,返回对应类别\n",
    "        if len(labels) == 1:\n",
    "            return DecisionTree(result=list(labels)[0])\n",
    "        \n",
    "        # 遍历完所有特征时,只剩下label标签,就返回出现字数最多的类标签\n",
    "        if not self.all_feats:\n",
    "            return DecisionTree(result=np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "\n",
    "        # 超过最大深度,则停止,使用出现最多的参数作为该叶子节点的类\n",
    "        if self.max_depth and depth > self.max_depth:\n",
    "            return DecisionTree(result=np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "\n",
    "        # 如果剩余的样本数大于等于给定的参数 min_samples_split,\n",
    "        # 则不在进行分割, 直接返回类别中最多的类,该节点作为叶子节点\n",
    "        if self.min_samples_split >= data.shape[0]:\n",
    "            return DecisionTree(result=np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "\n",
    "        # 叶子节点个数小于指定参数就进行返回,叶子节点中的出现最多的类\n",
    "        if self.min_samples_leaf >= data.shape[0]:\n",
    "            return DecisionTree(result=np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "        \n",
    "        # 根据基尼指数选择每个分割的最优特征\n",
    "        best_idx, best_val, min_gini = self.__getBestFeature(data)\n",
    "        print (\"Current best Feature:\", best_idx, best_val, min_gini)\n",
    "        # 如果当前的gini指数小于指定阈值,直接返回\n",
    "        if min_gini < self.min_impurity_split:\n",
    "            return DecisionTree(result=np.argmax(np.bincount(data[:,-1].astype(int))))\n",
    "        \n",
    "        leftData, rightData = self.__splitData(data, best_idx, best_val)\n",
    "        \n",
    "        #============================= show me your code =======================\n",
    "        # here\n",
    "        leftDecisionTree = self.__build_tree(leftData, depth+1)\n",
    "        rightDecisionTree = self.__build_tree(rightData, depth+1)\n",
    "        #============================= show me your code =======================\n",
    "        \n",
    "        return DecisionTree(col=best_idx, val=best_val, LeftChild=leftDecisionTree, RightChild=rightDecisionTree)\n",
    "\n",
    "    \n",
    "    def __getBestFeature(self, data):\n",
    "        \"\"\"得到最优特征对应的列\n",
    "        Paramters:\n",
    "        ---------\n",
    "        data: np.ndarray\n",
    "            从data中选择最优特征\n",
    "            \n",
    "        Returns:\n",
    "        -------\n",
    "        bestInx, val, 最优特征的列的索引和使用的值.\n",
    "        \"\"\"\n",
    "        best_idx = -1\n",
    "        best_val = None\n",
    "        min_gini = 1.0                \n",
    "        # 遍历现在可以使用的特征列\n",
    "        #============================= show me your code =======================\n",
    "\n",
    "        # here\n",
    "        min_gini = 0.0\n",
    "        currentGain = self.gini(data)\n",
    "        rows_length = len(data)\n",
    "\n",
    "        for col in self.all_feats:\n",
    "            col_value_set = set([x[col] for x in data])\n",
    "            for value in col_value_set:\n",
    "                list1,list2 = self.__splitData(data, col, value)\n",
    "                p = len(list1)/rows_length\n",
    "                gain = currentGain - p * self.gini(list1) - (1-p) * self.gini(list2)\n",
    "                if gain > min_gini:\n",
    "                    min_gini = gain\n",
    "                    best_idx = col\n",
    "                    best_val = value\n",
    "        \n",
    "        #============================= show me your code =======================\n",
    "        # 删除使用过的特征\n",
    "        self.all_feats.remove(best_idx)\n",
    "        \n",
    "        return best_idx, best_val, min_gini\n",
    "        \n",
    "    # add function\n",
    "    def calculateDiffCount(self, datas):\n",
    "        #将输入的数据汇总(input dataSet)\n",
    "        #return results Set{type1:type1Count,type2:type2Count ... typeN:typeNCount}\n",
    "\n",
    "        results = {}\n",
    "        for data in datas:\n",
    "            #data[-1] means dataType\n",
    "            if data[-1] not in results:\n",
    "                results[data[-1]] = 1\n",
    "            else:\n",
    "                results[data[-1]] += 1\n",
    "        return results\n",
    "    \n",
    "    def gini(self, labels):\n",
    "        \"\"\"计算基尼指数.\n",
    "        \n",
    "        Paramters:\n",
    "        ----------\n",
    "        labels: list or np.ndarray, 数据对应的类目集合.\n",
    "        \n",
    "        Returns: \n",
    "        -------\n",
    "        gini : float ``` Gini(p) = \\sum_{k=1}^{K}p_k(1-p_k)=1-\\sum_{k=1}^{K}p_k^2 ```\n",
    "        \n",
    "        \"\"\"\n",
    "        #============================= show me your code =======================\n",
    "\n",
    "        # here\n",
    "        length = len(labels)\n",
    "        results = self.calculateDiffCount(labels)\n",
    "        imp = 0.0\n",
    "        for i in results:\n",
    "            imp += results[i]/length * results[i]/length\n",
    "        gini = 1 - imp\n",
    "        \n",
    "        #============================= show me your code =======================\n",
    "        return gini\n",
    "    \n",
    "    \n",
    "    def __splitData(self, data, featColumn, val):\n",
    "        '''根据特征划分数据集分成左右两部分.\n",
    "        Paramters:\n",
    "        ---------\n",
    "        data: np.ndarray, 分割的数据\n",
    "        \n",
    "        featColumn : int, 使用第几列的数据进行分割\n",
    "        \n",
    "        val : int or float or str, 分割的值\n",
    "            int or float : 使用比较方式\n",
    "            str : 使用相等方式\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        leftData, RightData\n",
    "            int or left: leftData <= val < rightData\n",
    "            str : leftData = val and rightData != val\n",
    "        '''\n",
    "        if isinstance(val, str):\n",
    "            leftData = data[data[:, featColumn] == val]\n",
    "            rightData = data[data[:, featColumn] != val]\n",
    "        elif isinstance(val, int) or isinstance(val, float):\n",
    "            leftData = data[data[:, featColumn] <= val]\n",
    "            rightData = data[data[:, featColumn] > val]\n",
    "        return leftData, rightData\n",
    "    \n",
    "    \n",
    "    def __check_array(self, X):\n",
    "        \"\"\"检查数据类型\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : {array-like} of shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        \n",
    "        Retures\n",
    "        -------\n",
    "        X: {array-like} of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        if isinstance(X, list):\n",
    "            X = np.array(X)\n",
    "        if not isinstance(X, np.ndarray) and not isinstance(X, pd.DataFrame):\n",
    "            raise ValueError(\"输出数据不合法,目前只支持np.ndarray or pd.DataFrame\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best Feature: 2 1.9 0.3490570175438597\n",
      "Current best Feature: 3 1.7 0.44709702777569815\n",
      "Current best Feature: 0 4.9 0.022727747052071368\n",
      "Current best Feature: 1 2.7 0.0015419501133787303\n",
      "Classifier Score: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 分类树\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print (\"Classifier Score:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
